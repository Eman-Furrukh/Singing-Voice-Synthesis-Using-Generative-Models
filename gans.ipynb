{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2603cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports,\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import Resample\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df9521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files loaded: 2890\n",
      "Validation files loaded: 361\n",
      "Test files loaded: 362\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "processed_dir = \"VocalSet_processed\"\n",
    "splits = ['train', 'val', 'test']\n",
    "sample_rate = 22050\n",
    "duration = 4.0  # seconds\n",
    "data = {}  # To store file paths or audio data\n",
    "\n",
    "# Access and optionally load files\n",
    "for split in splits:\n",
    "    split_path = os.path.join(processed_dir, split)\n",
    "    file_paths = [os.path.join(split_path, f) for f in os.listdir(split_path) if f.endswith('.wav')]\n",
    "    \n",
    "    # Optionally: Load audio files\n",
    "    audio_data = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            y, _ = librosa.load(path, sr=sample_rate)\n",
    "            audio_data.append((path, y))  # or just y if you don’t need the path\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {path}: {e}\")\n",
    "    \n",
    "    data[split] = audio_data  # Contains (path, audio_array) for each file\n",
    "\n",
    "# Example usage\n",
    "print(f\"Train files loaded: {len(data['train'])}\")\n",
    "print(f\"Validation files loaded: {len(data['val'])}\")\n",
    "print(f\"Test files loaded: {len(data['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165b4ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 180/180 [17:55<00:00,  5.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Loss_D: 2.7504, Loss_G: 82.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 180/180 [17:07<00:00,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] Loss_D: 0.4604, Loss_G: 84.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 180/180 [17:20<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] Loss_D: 0.3689, Loss_G: 87.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 180/180 [17:37<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] Loss_D: 0.6819, Loss_G: 37.9613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 180/180 [16:53<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] Loss_D: 0.4746, Loss_G: 71.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 180/180 [15:48<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] Loss_D: 0.3510, Loss_G: 50.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 180/180 [15:06<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] Loss_D: 0.3363, Loss_G: 33.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 180/180 [15:02<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] Loss_D: 0.3288, Loss_G: 43.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 180/180 [14:54<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] Loss_D: 0.6036, Loss_G: 27.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 180/180 [14:59<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] Loss_D: 0.4364, Loss_G: 24.2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 180/180 [14:50<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] Loss_D: 0.3326, Loss_G: 38.5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 180/180 [16:20<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] Loss_D: 0.3397, Loss_G: 36.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 180/180 [17:09<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] Loss_D: 0.4921, Loss_G: 26.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 180/180 [16:59<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] Loss_D: 0.3331, Loss_G: 50.8038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 180/180 [16:52<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] Loss_D: 0.3377, Loss_G: 25.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 180/180 [16:44<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] Loss_D: 0.3448, Loss_G: 30.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 180/180 [16:46<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] Loss_D: 0.3399, Loss_G: 31.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 180/180 [17:13<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] Loss_D: 0.3312, Loss_G: 55.7919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 180/180 [15:20<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] Loss_D: 0.3308, Loss_G: 35.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 180/180 [15:34<00:00,  5.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] Loss_D: 0.3348, Loss_G: 31.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 180/180 [15:36<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] Loss_D: 0.3759, Loss_G: 38.1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 180/180 [15:54<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] Loss_D: 0.3486, Loss_G: 36.9954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 180/180 [15:49<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] Loss_D: 0.3389, Loss_G: 20.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 180/180 [15:34<00:00,  5.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] Loss_D: 0.4897, Loss_G: 52.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 180/180 [15:29<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] Loss_D: 0.3370, Loss_G: 34.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 180/180 [15:28<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] Loss_D: 0.3623, Loss_G: 33.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 180/180 [15:28<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] Loss_D: 0.3262, Loss_G: 28.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 180/180 [15:28<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] Loss_D: 0.3279, Loss_G: 33.7441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 180/180 [15:26<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] Loss_D: 0.3298, Loss_G: 24.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 180/180 [15:21<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] Loss_D: 0.3266, Loss_G: 22.3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 180/180 [15:13<00:00,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] Loss_D: 0.3271, Loss_G: 30.2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 180/180 [15:09<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] Loss_D: 0.3271, Loss_G: 45.3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 180/180 [15:16<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] Loss_D: 0.3325, Loss_G: 18.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 180/180 [16:44<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] Loss_D: 0.3363, Loss_G: 25.4705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 180/180 [16:45<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] Loss_D: 0.3278, Loss_G: 19.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 180/180 [17:38<00:00,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] Loss_D: 0.3270, Loss_G: 17.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 180/180 [18:11<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] Loss_D: 0.3280, Loss_G: 24.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 180/180 [18:54<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] Loss_D: 0.3279, Loss_G: 30.3532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 180/180 [17:52<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] Loss_D: 0.3299, Loss_G: 36.0546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 180/180 [15:48<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] Loss_D: 0.3254, Loss_G: 28.9557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 180/180 [17:02<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] Loss_D: 0.3266, Loss_G: 36.5267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 180/180 [19:46<00:00,  6.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] Loss_D: 0.3273, Loss_G: 28.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 180/180 [22:20<00:00,  7.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] Loss_D: 0.3340, Loss_G: 20.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 180/180 [18:15<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] Loss_D: 0.3260, Loss_G: 33.2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100:  26%|██▌       | 47/180 [05:05<14:24,  6.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    108\u001b[39m     outputs = discriminator(fake_audio)\n\u001b[32m    109\u001b[39m     loss_G = criterion(outputs, real_labels)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[43mloss_G\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     optimizer_G.step()\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Loss_D: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_D.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss_G: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_G.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\OneDrive\\Documents\\FAST\\SEMESTER VIII\\GenerativeAI\\Project\\myenv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\OneDrive\\Documents\\FAST\\SEMESTER VIII\\GenerativeAI\\Project\\myenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\OneDrive\\Documents\\FAST\\SEMESTER VIII\\GenerativeAI\\Project\\myenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "\n",
    "# CONFIG\n",
    "DATA_DIR = 'VocalSet_processed'\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 4.0\n",
    "AUDIO_LENGTH = int(SAMPLE_RATE * DURATION)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = \"gan_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ==== Dataset ====\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, split_dir):\n",
    "        self.files = [os.path.join(split_dir, f) for f in os.listdir(split_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        audio, _ = librosa.load(path, sr=SAMPLE_RATE)\n",
    "        audio = librosa.util.fix_length(audio, size=AUDIO_LENGTH)\n",
    "        return torch.tensor(audio, dtype=torch.float32)\n",
    "\n",
    "# ==== Models ====\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(2048, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ==== DataLoader ====\n",
    "train_dataset = AudioDataset(os.path.join(DATA_DIR, \"train\"))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "# ==== Initialize Models ====\n",
    "generator = Generator(LATENT_DIM, AUDIO_LENGTH).to(DEVICE)\n",
    "discriminator = Discriminator(AUDIO_LENGTH).to(DEVICE)\n",
    "\n",
    "# ==== Optimizers and Loss ====\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# ==== Training Loop ====\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        real_labels = torch.full((BATCH_SIZE, 1), 0.9).to(DEVICE)  # label smoothing\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "        # === Train Discriminator ===\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs_real = discriminator(batch)\n",
    "        loss_real = criterion(outputs_real, real_labels)\n",
    "\n",
    "        z = torch.randn(BATCH_SIZE, LATENT_DIM).to(DEVICE)\n",
    "        fake_audio = generator(z)\n",
    "        outputs_fake = discriminator(fake_audio.detach())\n",
    "        loss_fake = criterion(outputs_fake, fake_labels)\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_audio)\n",
    "        loss_G = criterion(outputs, real_labels)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "    # === Save sample audio ===\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, LATENT_DIM).to(DEVICE)\n",
    "            gen_audio = generator(z).cpu().numpy().flatten()\n",
    "            sf.write(f\"{OUTPUT_DIR}/sample_epoch_{epoch+1}.wav\", gen_audio, SAMPLE_RATE)\n",
    "        generator.train()\n",
    "\n",
    "# ==== Save models ====\n",
    "torch.save(generator.state_dict(), os.path.join(OUTPUT_DIR, \"generator.pth\"))\n",
    "torch.save(discriminator.state_dict(), os.path.join(OUTPUT_DIR, \"discriminator.pth\"))\n",
    "print(\"Models saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f068b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_27324\\4250236396.py:139: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\Users\\DELL\\OneDrive\\Documents\\FAST\\SEMESTER VIII\\GenerativeAI\\Project\\myenv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Epoch 1/50:   0%|          | 0/90 [00:00<?, ?it/s]c:\\Users\\DELL\\OneDrive\\Documents\\FAST\\SEMESTER VIII\\GenerativeAI\\Project\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# === CONFIG ===\n",
    "DATA_DIR = 'VocalSet_processed'\n",
    "SAMPLE_RATE = 16000  # Reduced sample rate\n",
    "DURATION = 2.0  # Reduced duration to 2 seconds\n",
    "AUDIO_LENGTH = int(SAMPLE_RATE * DURATION)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LATENT_DIM = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = \"gan_outputs_improved\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Dataset ===\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, split_dir):\n",
    "        self.files = [os.path.join(split_dir, f) for f in os.listdir(split_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        waveform = torch.mean(waveform, dim=0)  # mono\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.functional.resample(waveform, orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, max(0, AUDIO_LENGTH - waveform.size(0))))\n",
    "        waveform = waveform[:AUDIO_LENGTH]\n",
    "        return waveform\n",
    "\n",
    "# === Generator ===\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256 * 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 64)),\n",
    "            nn.ConvTranspose1d(256, 128, 25, stride=4, padding=11, output_padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(128, 64, 25, stride=4, padding=11, output_padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(64, 1, 25, stride=2, padding=12, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.model(z)\n",
    "        x = x.squeeze(1)\n",
    "        if x.size(1) < AUDIO_LENGTH:\n",
    "            x = torch.nn.functional.pad(x, (0, AUDIO_LENGTH - x.size(1)))\n",
    "        return x[:, :AUDIO_LENGTH]\n",
    "\n",
    "# === Discriminator ===\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 25, stride=4, padding=11),  # Reduced number of channels\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(32, 64, 25, stride=4, padding=11),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(64, 128, 25, stride=4, padding=11),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        # Compute output size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 1, AUDIO_LENGTH)\n",
    "            out = self.features(dummy_input)\n",
    "            self.flattened_size = out.view(1, -1).size(1)\n",
    "\n",
    "        self.classifier = nn.Linear(self.flattened_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [B, 1, AUDIO_LENGTH]\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# === Gradient Penalty ===\n",
    "def gradient_penalty(D, real, fake):\n",
    "    batch_size = real.size(0)\n",
    "    alpha = torch.rand(batch_size, 1).to(DEVICE)\n",
    "    alpha = alpha.expand_as(real)\n",
    "\n",
    "    interpolates = alpha * real + (1 - alpha) * fake\n",
    "    interpolates = interpolates.requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "    ones = torch.ones_like(d_interpolates).to(DEVICE)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=ones,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty\n",
    "\n",
    "# === DataLoader ===\n",
    "train_dataset = AudioDataset(os.path.join(DATA_DIR, \"train\"))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    num_workers=8,  # Increased number of workers\n",
    "    pin_memory=True  # Enable memory pinning for faster transfer to GPU\n",
    ")\n",
    "\n",
    "# === Model Initialization ===\n",
    "generator = Generator(LATENT_DIM).to(DEVICE)\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "\n",
    "# === Optimizers ===\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "# === Mixed Precision Training ===\n",
    "scaler = GradScaler()\n",
    "\n",
    "# === Training Loop ===\n",
    "lambda_gp = 10\n",
    "n_critic = 1  # Reduced from 2 to 1 to speed up training\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")):\n",
    "        real_audio = batch.to(DEVICE)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(BATCH_SIZE, LATENT_DIM).to(DEVICE)\n",
    "        fake_audio = generator(z).detach()\n",
    "\n",
    "        for _ in range(n_critic):\n",
    "            with autocast():\n",
    "                d_real = discriminator(real_audio)\n",
    "                d_fake = discriminator(fake_audio)\n",
    "                gp = gradient_penalty(discriminator, real_audio, fake_audio)\n",
    "                loss_D = -(torch.mean(d_real) - torch.mean(d_fake)) + lambda_gp * gp\n",
    "\n",
    "            scaler.scale(loss_D).backward()\n",
    "            scaler.step(optimizer_D)\n",
    "            scaler.update()\n",
    "\n",
    "        # Train Generator\n",
    "        z = torch.randn(BATCH_SIZE, LATENT_DIM).to(DEVICE)\n",
    "        fake_audio = generator(z)\n",
    "\n",
    "        with autocast():\n",
    "            loss_G = -torch.mean(discriminator(fake_audio))\n",
    "\n",
    "        scaler.scale(loss_G).backward()\n",
    "        scaler.step(optimizer_G)\n",
    "        scaler.update()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, LATENT_DIM).to(DEVICE)\n",
    "            gen_audio = generator(z).cpu().numpy().flatten()\n",
    "            sf.write(f\"{OUTPUT_DIR}/sample_epoch_{epoch+1}.wav\", gen_audio, SAMPLE_RATE)\n",
    "        generator.train()\n",
    "\n",
    "# === Save Models ===\n",
    "torch.save(generator.state_dict(), os.path.join(OUTPUT_DIR, \"generator.pth\"))\n",
    "torch.save(discriminator.state_dict(), os.path.join(OUTPUT_DIR, \"discriminator.pth\"))\n",
    "print(\"Models saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa934acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 180/180 [49:19<00:00, 16.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Avg Loss_D: 0.9690, Avg Loss_G: 6.4710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 180/180 [38:38<00:00, 12.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] Avg Loss_D: 0.8485, Avg Loss_G: 6.8569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 180/180 [34:34<00:00, 11.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] Avg Loss_D: 0.9552, Avg Loss_G: 5.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 180/180 [29:56<00:00,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] Avg Loss_D: 0.6479, Avg Loss_G: 5.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 180/180 [29:25<00:00,  9.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] Avg Loss_D: 0.7573, Avg Loss_G: 5.2758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 180/180 [29:23<00:00,  9.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] Avg Loss_D: 0.7926, Avg Loss_G: 4.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 180/180 [33:51<00:00, 11.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] Avg Loss_D: 0.8733, Avg Loss_G: 4.3537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 180/180 [34:22<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] Avg Loss_D: 0.9979, Avg Loss_G: 3.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 180/180 [30:43<00:00, 10.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] Avg Loss_D: 0.9340, Avg Loss_G: 3.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 180/180 [29:45<00:00,  9.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] Avg Loss_D: 1.0730, Avg Loss_G: 2.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 180/180 [29:26<00:00,  9.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] Avg Loss_D: 1.0297, Avg Loss_G: 2.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 180/180 [29:29<00:00,  9.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] Avg Loss_D: 1.0233, Avg Loss_G: 1.4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 180/180 [32:34<00:00, 10.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] Avg Loss_D: 1.0192, Avg Loss_G: 1.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 180/180 [34:15<00:00, 11.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] Avg Loss_D: 1.0012, Avg Loss_G: 1.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 180/180 [34:12<00:00, 11.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] Avg Loss_D: 1.0163, Avg Loss_G: 1.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 180/180 [35:42<00:00, 11.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] Avg Loss_D: 1.0275, Avg Loss_G: 1.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 180/180 [34:58<00:00, 11.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] Avg Loss_D: 0.9838, Avg Loss_G: 1.1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 180/180 [29:21<00:00,  9.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] Avg Loss_D: 1.0122, Avg Loss_G: 1.1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 180/180 [31:30<00:00, 10.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] Avg Loss_D: 1.0219, Avg Loss_G: 1.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 180/180 [35:34<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] Avg Loss_D: 1.0030, Avg Loss_G: 1.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 180/180 [29:48<00:00,  9.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] Avg Loss_D: 0.9935, Avg Loss_G: 1.2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 180/180 [28:52<00:00,  9.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] Avg Loss_D: 1.0246, Avg Loss_G: 1.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 180/180 [28:43<00:00,  9.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] Avg Loss_D: 1.0212, Avg Loss_G: 1.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 180/180 [28:57<00:00,  9.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] Avg Loss_D: 1.0338, Avg Loss_G: 1.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 180/180 [28:51<00:00,  9.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] Avg Loss_D: 0.9877, Avg Loss_G: 1.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 180/180 [29:06<00:00,  9.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] Avg Loss_D: 1.0109, Avg Loss_G: 1.2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 180/180 [28:56<00:00,  9.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] Avg Loss_D: 0.9908, Avg Loss_G: 1.2423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 180/180 [28:59<00:00,  9.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] Avg Loss_D: 0.9947, Avg Loss_G: 1.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 180/180 [28:49<00:00,  9.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] Avg Loss_D: 1.0256, Avg Loss_G: 1.2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 180/180 [28:58<00:00,  9.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] Avg Loss_D: 0.9784, Avg Loss_G: 1.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 180/180 [28:54<00:00,  9.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] Avg Loss_D: 1.1015, Avg Loss_G: 1.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 180/180 [28:52<00:00,  9.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] Avg Loss_D: 1.1094, Avg Loss_G: 1.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 180/180 [28:49<00:00,  9.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] Avg Loss_D: 1.1055, Avg Loss_G: 1.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 180/180 [29:06<00:00,  9.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] Avg Loss_D: 1.1135, Avg Loss_G: 1.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 180/180 [28:58<00:00,  9.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] Avg Loss_D: 1.1215, Avg Loss_G: 1.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 180/180 [29:02<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] Avg Loss_D: 1.1263, Avg Loss_G: 1.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 180/180 [29:40<00:00,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] Avg Loss_D: 1.1187, Avg Loss_G: 1.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 180/180 [34:01<00:00, 11.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] Avg Loss_D: 1.1226, Avg Loss_G: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 180/180 [34:00<00:00, 11.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] Avg Loss_D: 1.1147, Avg Loss_G: 1.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 180/180 [36:02<00:00, 12.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] Avg Loss_D: 1.1307, Avg Loss_G: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 180/180 [36:20<00:00, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] Avg Loss_D: 1.1185, Avg Loss_G: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 180/180 [34:29<00:00, 11.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] Avg Loss_D: 1.1357, Avg Loss_G: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 180/180 [35:47<00:00, 11.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] Avg Loss_D: 1.1377, Avg Loss_G: 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 180/180 [1:03:02<00:00, 21.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] Avg Loss_D: 1.1266, Avg Loss_G: 0.9822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100:  68%|██████▊   | 122/180 [37:51<11:52, 12.29s/it] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import random\n",
    "\n",
    "# CONFIG\n",
    "DATA_DIR = 'VocalSet_processed'\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 4.0\n",
    "AUDIO_LENGTH = int(SAMPLE_RATE * DURATION)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = \"gan_outputs_improved\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ==== Dataset ====\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, split_dir):\n",
    "        self.files = [os.path.join(split_dir, f) for f in os.listdir(split_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        audio, _ = librosa.load(path, sr=SAMPLE_RATE)\n",
    "        audio = librosa.util.fix_length(audio, size=AUDIO_LENGTH)\n",
    "        return torch.tensor(audio, dtype=torch.float32)\n",
    "\n",
    "# ==== Models ====\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(2048, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Linear(input_size, 2048)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.utils.spectral_norm(nn.Linear(2048, 1024)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.utils.spectral_norm(nn.Linear(1024, 1))\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ==== DataLoader ====\n",
    "train_dataset = AudioDataset(os.path.join(DATA_DIR, \"train\"))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "# ==== Initialize Models ====\n",
    "generator = Generator(LATENT_DIM, AUDIO_LENGTH).to(DEVICE)\n",
    "discriminator = Discriminator(AUDIO_LENGTH).to(DEVICE)\n",
    "\n",
    "# ==== Optimizers and Loss ====\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Learning Rate Schedulers\n",
    "scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=30, gamma=0.5)\n",
    "scheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=30, gamma=0.5)\n",
    "\n",
    "# ==== Training Loop ====\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss_D = 0.0\n",
    "    total_loss_G = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # Label smoothing and flipping\n",
    "        real_labels = torch.full((BATCH_SIZE, 1), 0.9).to(DEVICE)\n",
    "        fake_labels = torch.zeros((BATCH_SIZE, 1)).to(DEVICE)\n",
    "\n",
    "        if random.random() < 0.05:  # Randomly flip labels (5% chance)\n",
    "            real_labels, fake_labels = fake_labels, real_labels\n",
    "\n",
    "        # === Train Discriminator ===\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs_real = discriminator(batch)\n",
    "        loss_real = criterion(outputs_real, real_labels)\n",
    "\n",
    "        z = torch.randn(BATCH_SIZE, LATENT_DIM).to(DEVICE)\n",
    "        fake_audio = generator(z)\n",
    "        outputs_fake = discriminator(fake_audio.detach())\n",
    "        loss_fake = criterion(outputs_fake, fake_labels)\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_audio)\n",
    "        loss_G = criterion(outputs, real_labels)\n",
    "        loss_G.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n",
    "        optimizer_G.step()\n",
    "\n",
    "        total_loss_D += loss_D.item()\n",
    "        total_loss_G += loss_G.item()\n",
    "\n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "\n",
    "    avg_loss_D = total_loss_D / len(train_loader)\n",
    "    avg_loss_G = total_loss_G / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Avg Loss_D: {avg_loss_D:.4f}, Avg Loss_G: {avg_loss_G:.4f}\")\n",
    "\n",
    "    # === Save sample audio ===\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, LATENT_DIM).to(DEVICE)\n",
    "            gen_audio = generator(z).cpu().numpy().flatten()\n",
    "            sf.write(f\"{OUTPUT_DIR}/sample_epoch_{epoch+1}.wav\", gen_audio, SAMPLE_RATE)\n",
    "        generator.train()\n",
    "\n",
    "# ==== Save models ====\n",
    "torch.save(generator.state_dict(), os.path.join(OUTPUT_DIR, \"generator.pth\"))\n",
    "torch.save(discriminator.state_dict(), os.path.join(OUTPUT_DIR, \"discriminator.pth\"))\n",
    "print(\"Models saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
